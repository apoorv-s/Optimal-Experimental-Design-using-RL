{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669d9aed-6e6c-4eeb-b212-6a0b97f4575a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import LightSource\n",
    "\n",
    "from tensorboard.backend.event_processing import event_accumulator\n",
    "import pandas as pd\n",
    "\n",
    "from src.OED import *\n",
    "from src.DQN import DQNConfig, DQN_OED\n",
    "from src.GA import *\n",
    "from pde.AdvectionEquation import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74beba4c-ca67-4a7f-b5f8-c406be22866a",
   "metadata": {},
   "source": [
    "## Evaluating models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7233e8bb-cee9-4804-a6ee-0cf1624c4ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pde_system = Advection2D(Adv2dModelConfig())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefd9ea9-b9df-4db4-881f-1df620bd3a88",
   "metadata": {},
   "source": [
    "### Old action space model : Seed 1, run 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84057c0-5206-4811-a974-97f55f036638",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "run_num = 17\n",
    "model_name = f'trained_model/Adv_old/Advection2D_old_dqn_{run_num}_seed_{seed}.zip'\n",
    "config_path = f'trained_model/Adv_old/Advection2D_old_dqn_{run_num}_seed_{seed}_config.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccb1cea-1928-4b95-8147-d063e9372a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = torch.load(config_path, weights_only=False)\n",
    "\n",
    "# Access individual configs\n",
    "gym_config = configs[\"gym_config\"]\n",
    "dqn_config = configs[\"dqn_config\"]\n",
    "tensorboard_dir = configs[\"tensorboard_log\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d3b979-008e-49d8-89f5-26881e6b99ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "gym_config.old_action_space = True\n",
    "dqn_old = DQN_OED(seed, pde_system, gym_config, dqn_config, verbose=1)\n",
    "dqn_old.load(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7269f6a4-c940-4ecb-ac7b-21ef8b016001",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_a_all_ep_rewards, old_a_best_rewards, old_a_optimal_states_all = dqn_old.evaluate(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d532f7-43da-4c10-9580-15cb781d049a",
   "metadata": {},
   "source": [
    "## New Action space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6cc658-0645-4923-a4e6-d99fde375f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "run_num = 1\n",
    "model_name = f'trained_model/Advection2D_new_dqn_{run_num}_seed_{seed}.zip'\n",
    "config_path = f'trained_model/Advection2D_new_dqn_{run_num}_seed_{seed}_config.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f5b433-f01e-44ce-a72e-10b81da8d9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = torch.load(config_path, weights_only=False)\n",
    "\n",
    "# Access individual configs\n",
    "gym_config = configs[\"gym_config\"]\n",
    "dqn_config = configs[\"dqn_config\"]\n",
    "tensorboard_dir = configs[\"tensorboard_log\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c14ec11-e6d5-4a4b-8125-7a0170030d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "gym_config.old_action_space = False\n",
    "dqn_new = DQN_OED(seed, pde_system, gym_config, dqn_config, verbose=1)\n",
    "dqn_new.load(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4bc307-7bc7-464d-b3f3-a86734eec815",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_a_all_ep_rewards, new_a_best_rewards, new_a_optimal_states_all = dqn_new.evaluate(num_episodes=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e01a04-d951-40eb-9692-354345f79ed3",
   "metadata": {},
   "source": [
    "## GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d83ae5-180a-4441-b862-965b0d7b9e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_filename = \"GAResults/Advection2D_ga_3.mat\"\n",
    "ga_res = scipy.io.loadmat(ga_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea24854-2bd3-4b63-9496-8b52bb1f9c1d",
   "metadata": {},
   "source": [
    "### MCTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b398d1a4-6b54-4ad7-ac04-6f0e3e694bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcts_res = scipy.io.loadmat('MCTS_results/mcts_results.mat')\n",
    "mcts_best_rew = mcts_res['best_rewards'].squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa2deda-7f8f-4337-a8b9-6df3ff921d5d",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbc6683-11d1-4346-afc2-24097f09b366",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = dqn_old.env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfdccab-b8c3-4c74-bb70-d59620ffae15",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Solution and Modes\n",
    "\n",
    "fig = plt.figure(figsize=(12, 12)) \n",
    "\n",
    "x = np.linspace(0, 1, env.nx)\n",
    "y = np.linspace(0, 1, env.ny)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "\n",
    "datasets = [\n",
    "    (env.pde_field[:, :, 0].T, rf\"Solution at $t = {env.pde_system.t_steps[0]}$\"),\n",
    "    (env.pde_field[:, :, -1].T, rf\"Solution at $t = {env.pde_system.t_steps[-1]}$\"),\n",
    "    (env.modes[:, 0].reshape(env.nx, env.ny).T, \"First KLD Mode\"),\n",
    "    (env.modes[:, 1].reshape(env.nx, env.ny).T, \"Second KLD Mode\")\n",
    "]\n",
    "\n",
    "for i, (data, title) in enumerate(datasets):\n",
    "    ax = fig.add_subplot(2, 2, i + 1, projection='3d')\n",
    "    \n",
    "    ls = LightSource(azdeg=315, altdeg=-65)\n",
    "    shaded = ls.shade(data, cmap=cm.coolwarm, vert_exag=0.1, blend_mode='soft')\n",
    "\n",
    "    surf = ax.plot_surface(X, Y, data, cmap='plasma', edgecolor='none', alpha=0.9)\n",
    "    \n",
    "    ax.set_title(title, fontsize=14, pad=10)\n",
    "    ax.set_xlabel(r'$x_1$', fontsize=12, labelpad=10)\n",
    "    ax.set_ylabel(r'$x_2$', fontsize=12, labelpad=10)\n",
    "    # ax.set_zlabel(r'$u(x_1, x_2)$', fontsize=12, labelpad=10)\n",
    "\n",
    "    ax.view_init(elev=35, azim=-135)\n",
    "\n",
    "    fig.colorbar(surf, ax=ax, fraction=0.046, pad=0.04)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"3D_Adv2d_2x2.png\", dpi=400, bbox_inches='tight')\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b150dcf-31cf-4d3a-a5b7-d08136c3c05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# log_dir = 'trained_model/Adv_old/DQN_20/'\n",
    "# tags = ['rollout/ep_rew_mean', 'train/loss']\n",
    "\n",
    "# # Load the TensorBoard data\n",
    "# ea = event_accumulator.EventAccumulator(\n",
    "#     log_dir,\n",
    "#     size_guidance={\n",
    "#         event_accumulator.SCALARS: 0,\n",
    "#     }\n",
    "# )\n",
    "# ea.Reload()\n",
    "\n",
    "# available_tags = ea.Tags()['scalars']\n",
    "\n",
    "# fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))\n",
    "\n",
    "# data_rew_mean = ea.Scalars('rollout/ep_rew_mean')\n",
    "# df_rew_mean = pd.DataFrame(data_rew_mean)\n",
    "\n",
    "# ax1.plot(df_rew_mean.step, df_rew_mean.value, label='rollout/ep_rew_mean', color='blue')\n",
    "# ax1.set_title('Rollout Episode Reward Mean')\n",
    "# # ax1.set_xlabel('Step')\n",
    "# ax1.set_ylabel('Reward')\n",
    "# ax1.legend()\n",
    "\n",
    "# data_loss = ea.Scalars('train/loss')\n",
    "# df_loss = pd.DataFrame(data_loss)\n",
    "\n",
    "# ax2.plot(df_loss.step, df_loss.value, label='train/loss', color='orange')\n",
    "# ax2.set_title('Training Loss')\n",
    "# ax2.set_xlabel('Step')\n",
    "# ax2.set_ylabel('Loss')\n",
    "# ax2.set_yscale('log')\n",
    "# ax2.legend()\n",
    "\n",
    "# plt.tight_layout()\n",
    "# # plt.savefig(\"old_dqn_adv2d.pdf\", dpi=400, bbox_inches='tight')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b9836b-8dcd-4baf-b56b-cf9afaf175df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New DQN: Training and reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5048efb7-7643-4cec-80b2-d9c4456716aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# log_dir = 'trained_model/Adv_new/DQN_1/'\n",
    "# tags = ['rollout/ep_rew_mean', 'train/loss']\n",
    "\n",
    "# # Load the TensorBoard data\n",
    "# ea = event_accumulator.EventAccumulator(\n",
    "#     log_dir,\n",
    "#     size_guidance={\n",
    "#         event_accumulator.SCALARS: 0,\n",
    "#     }\n",
    "# )\n",
    "# ea.Reload()\n",
    "\n",
    "# available_tags = ea.Tags()['scalars']\n",
    "\n",
    "# fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))\n",
    "\n",
    "# data_rew_mean = ea.Scalars('rollout/ep_rew_mean')\n",
    "# df_rew_mean = pd.DataFrame(data_rew_mean)\n",
    "\n",
    "# ax1.plot(df_rew_mean.step, df_rew_mean.value, label='rollout/ep_rew_mean', color='blue')\n",
    "# ax1.set_title('Rollout Episode Reward Mean')\n",
    "# # ax1.set_xlabel('Step')\n",
    "# ax1.set_ylabel('Reward')\n",
    "# ax1.legend()\n",
    "\n",
    "# data_loss = ea.Scalars('train/loss')\n",
    "# df_loss = pd.DataFrame(data_loss)\n",
    "\n",
    "# ax2.plot(df_loss.step, df_loss.value, label='train/loss', color='orange')\n",
    "# ax2.set_title('Training Loss')\n",
    "# ax2.set_xlabel('Step')\n",
    "# ax2.set_ylabel('Loss')\n",
    "# ax2.set_yscale('log')\n",
    "# ax2.legend()\n",
    "\n",
    "# plt.tight_layout()\n",
    "# # plt.savefig(\"new_dqn_adv2d.pdf\", dpi=400, bbox_inches='tight')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551974fd-42e3-47ae-9382-91aead7414e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reward distribution comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426dbfb0-d749-45ff-a0bd-c84e87cbdd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "plt.hist(mcts_best_rew, bins=20, \n",
    "         color='#8C00',\n",
    "         edgecolor='white', \n",
    "         linewidth=1.5, \n",
    "         alpha=0.6, \n",
    "         density=True,  # Normalize densities\n",
    "         label='MCTS')\n",
    "\n",
    "plt.hist(old_a_best_rewards, bins=20, \n",
    "         color='#4F94CD',\n",
    "         edgecolor='white', \n",
    "         linewidth=1.5, \n",
    "         alpha=0.6, \n",
    "         density=True,  # Normalize densities\n",
    "         label='Old Action Space')\n",
    "\n",
    "plt.hist(new_a_best_rewards, bins=20, \n",
    "         color='#FF8C00',\n",
    "         edgecolor='white', \n",
    "         linewidth=1.5, \n",
    "         alpha=0.6, \n",
    "         density=True,  # Normalize densities\n",
    "         label='New Action space')\n",
    "\n",
    "\n",
    "\n",
    "mean_old = np.mean(old_a_best_rewards)\n",
    "mean_new = np.mean(new_a_best_rewards)\n",
    "mean_mcts = np.mean(mcts_best_rew)\n",
    "ga_best = ga_res['best_fitness'][0][0]\n",
    "\n",
    "plt.axvline(x=mean_old, color='#4F94CD', linestyle='--', linewidth=2, label=f'Mean (Old A): {mean_old:.2f}')\n",
    "plt.axvline(x=mean_new, color='#FF8C00', linestyle='--', linewidth=2, label=f'Mean (New A): {mean_new:.2f}')\n",
    "plt.axvline(x=ga_best, color='g', linestyle='--', linewidth=2, label=f'GA (Best): {ga_best:.2f}')\n",
    "plt.axvline(x=mean_mcts, color='r', linestyle='--', linewidth=2, label=f'Mean MCTS: {mean_mcts:.2f}')\n",
    "\n",
    "plt.xlabel('Episode Best Reward', fontsize=18)\n",
    "plt.ylabel('Density', fontsize=18)\n",
    "plt.tick_params(axis='both', which='major', labelsize=18)\n",
    "plt.legend(fontsize=16)\n",
    "plt.ylim([0, 30])\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"adv2d_res_hist.png\", dpi=400, bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cs234_a3]",
   "language": "python",
   "name": "conda-env-cs234_a3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
